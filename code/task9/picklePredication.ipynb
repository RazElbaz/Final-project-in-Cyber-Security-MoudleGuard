{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107aeba8",
   "metadata": {},
   "source": [
    "<img src=\"ariel.png\" alt=\"Image 1\" width=\"150\" style=\"float: left; margin-right: 20px;\">\n",
    "<img src=\"cyber.png\" alt=\"Image 2\" width=\"150\" style=\"float: left;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb569a1b",
   "metadata": {},
   "source": [
    "# ModelGuard: disarm and reconstruction\n",
    "### Raz Elbaz\n",
    "### Dr. Ran Dubin and Prof. Amit Dvir\n",
    "\n",
    "#### Student ID: 207276775\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732911f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c923ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from mnist_sample import *\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "import fickling.analysis as analysis\n",
    "from fickling.pickle import Pickled\n",
    "import builtins\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "import pickle\n",
    "import ast\n",
    "import pickletools\n",
    "from typing import Optional, TextIO, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663e5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info < (3, 9):\n",
    "    from astunparse import unparse\n",
    "else:\n",
    "    from ast import unparse\n",
    "\n",
    "from fickling.pickle import Interpreter, Pickled\n",
    "class cdr:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def code(self, pickled: Pickled) -> str:\n",
    "        \"\"\"\n",
    "        Returns the string representation of the code object that was pickled.\n",
    "        \"\"\"\n",
    "        code = pickled['code']\n",
    "        return code.co_code.decode('utf-8')\n",
    "\n",
    "    def check_safety(\n",
    "        self, pickled: Pickled, filename, stdout: Optional[TextIO] = None, stderr: Optional[TextIO] = None\n",
    "    ) -> bool:\n",
    "        if stdout is None:\n",
    "            stdout = sys.stdout\n",
    "        if stderr is None:\n",
    "            stderr = sys.stderr\n",
    "\n",
    "        properties = pickled.properties\n",
    "        likely_safe = True\n",
    "        reported_shortened_code = set()\n",
    "\n",
    "        def shorten_code(ast_node) -> Tuple[str, bool]:\n",
    "            code = unparse(ast_node).strip()\n",
    "            if len(code) > 32:\n",
    "                cutoff = code.find(\"(\")\n",
    "                if code[cutoff] == \"(\":\n",
    "                    shortened_code = f\"{code[:code.find('(')].strip()}(...)\"\n",
    "                else:\n",
    "                    shortened_code = code\n",
    "            else:\n",
    "                shortened_code = code\n",
    "            was_already_reported = shortened_code in reported_shortened_code\n",
    "            reported_shortened_code.add(shortened_code)\n",
    "            return shortened_code, was_already_reported\n",
    "\n",
    "        safe_lines = []\n",
    "\n",
    "        with open(filename, 'rb') as f:\n",
    "            code = str(f.read().decode('latin1'))\n",
    "\n",
    "        for line in code.split('\\n'):\n",
    "            try:\n",
    "                clean_string = line.replace('\\x00', '')\n",
    "                ast_node = compile(clean_string, '<string>', 'exec', ast.PyCF_ONLY_AST)\n",
    "            except SyntaxError:\n",
    "                continue\n",
    "            is_safe = True\n",
    "            for node in ast.walk(ast_node):\n",
    "                if isinstance(node, ast.Call):\n",
    "                    if (\n",
    "                        isinstance(node.func, ast.Name)\n",
    "                        and node.func.id == 'eval'\n",
    "                    ):\n",
    "                        is_safe = False\n",
    "                    elif (\n",
    "                        isinstance(node.func, ast.Attribute)\n",
    "                        and node.func.attr == 'loads'\n",
    "                        and isinstance(node.func.value, ast.Name)\n",
    "                        and node.func.value.id == 'pickle'\n",
    "                    ):\n",
    "                        is_safe = False\n",
    "                elif isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        if not alias.name.startswith('_') and alias.name not in sys.modules:\n",
    "                            is_safe = False\n",
    "                elif isinstance(node, ast.ImportFrom):\n",
    "                    if not node.module.startswith('_') and node.module not in sys.modules:\n",
    "                        is_safe = False\n",
    "                elif (\"eval\" in line) or (\"exec\" in line) or (\"compile\" in line) or (\"open\" in line):\n",
    "                    is_safe = False\n",
    "                elif (\"__builtin__\"in line) or (\"os\" in line) or (\"subprocess\" in line) or (\"sys\" in line) or (\"builtins\" in line) or (\"socket\" in line):\n",
    "                    is_safe = False\n",
    "\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = f.read()\n",
    "\n",
    "        for op in pickletools.genops(data):\n",
    "            if type(op[1]) == str and all(substring not in op[1] for substring in [\"eval\", \"exec\", \"compile\", \"open\", \"__builtin__\", \"os\", \"subprocess\", \"sys\", \"builtins\", \"socket\"]):\n",
    "                safe_lines.append(op[1])\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump('\\n'.join(safe_lines), f)\n",
    "\n",
    "        if not safe_lines:\n",
    "            return \"False\"\n",
    "\n",
    "        if likely_safe:\n",
    "            return \"True\"\n",
    "        else:\n",
    "            return \"False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0d28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    display(Markdown(\"-------------------------- \" + os.path.splitext(filename)[0] + \" ----------------------------------\"))\n",
    "    \n",
    "    with patch('sys.stdout') as stdout:\n",
    "            \n",
    "        with open(filename, 'rb') as f:\n",
    "                pickled_data = f.read()\n",
    "        pickled_obj = Pickled.load(pickled_data)\n",
    "            # First run analysis.py\n",
    "        analysis_result = analysis.check_safety(pickled_obj)\n",
    "        display(str(analysis_result)) # Expecting clean\n",
    "        if str(analysis_result) == '':\n",
    "            display(Markdown(\"clean\"))\n",
    "        else:\n",
    "            display(Markdown(\"not clean\"))\n",
    "            scan_pickle_file.scann(filename)\n",
    "            display(Markdown(\"Now removing the malicious data....\"))\n",
    "            with patch('sys.stdout') as stdout:\n",
    "                cdr().check_safety(pickled_obj,filename)\n",
    "                \n",
    "                # Finally, run analysis.py again\n",
    "                with open(filename, 'rb') as f:\n",
    "                    pickled_data = f.read()\n",
    "                pickled_obj = Pickled.load(pickled_data)\n",
    "                analysis_result_2 = analysis.check_safety(pickled_obj)\n",
    "                display(str(analysis_result_2)) # Expecting clean\n",
    "            # Check stdout for expected messages\n",
    "            if str(analysis_result_2) == '':\n",
    "                display(Markdown(\"clean\"))\n",
    "                display(Markdown(\"\\nThe clean data left in the file:\"))\n",
    "                with open(filename, 'rb') as f:\n",
    "                    pickled_data = pickle.load(f)\n",
    "                display(str(pickled_data))\n",
    "            else:\n",
    "                display(Markdown(\"not clean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc1494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from fickling.pickle import Pickled\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "from termcolor import colored\n",
    "# -attacks\n",
    "# https://www.cadosecurity.com/linux-attack-techniques-dynamic-linker-hijacking-with-ld-preload/\n",
    "# https://www.cybertriage.com/blog/training/how-to-detect-running-malware-intro-to-incident-response-triage-part-7/\n",
    "\n",
    "# https://www.beyondtrust.com/blog/entry/important-linux-files-protect\n",
    "BAD_LIBRARY = {'/etc/hosts', '/bin/sh', '/etc/passwd', '/etc/pam.conf', '/proc', '/etc/shadow', '/etc/profile',\n",
    "               '~/.bash_profile', '~/.bash_login', '~/.profile. /home/user/.bashrc', '/etc/bash.bashrc',\n",
    "               '/etc/profile.d/', '/etc/system.d', '/etc/rc.*', '/etc/init.*.', '/etc/resolv.conf', '/etc/gshadow',\n",
    "               '/etc/pam.d', '/bin', '/sbin'}\n",
    "# This technique is often called DLL injection on Windows.\n",
    "# With DLL injection, the attacker creates a malicious library with the same name and API as the good one.\n",
    "# The program loads the malicious library and it, in turn, loads the good one and it will call the good one as needed to do the operations that the original program wants.\n",
    "BAD_CALLS = {'os', 'shutil', 'sys', 'requests', 'net', 'func',\n",
    "             'args',\n",
    "             'keywords', }\n",
    "BAD_SIGNAL = {'eval', 'compile', 'rm ', 'cat ', 'nc ', 'exec', 'open', 'run'}\n",
    "BAD_FILES = {'.py', '.exe', '.dll', '.so'}\n",
    "# https://redcanary.com/threat-detection-report/techniques/powershell/\n",
    "# PowerShell -encodedcommand switch\n",
    "# This detection analytic looks for the execution of powershell.exe with command lines that include variations of the -encodedcommand argument; PowerShell will recognize and accept anything from -e onward, and it will show up outside of the encoded bits.\n",
    "BAD_COMMAND = {'powershell.exe', '-e', '-en', '-enc', '-enco', 'ls', 'base64'}\n",
    "# Obfuscation and escape characters\n",
    "# Obfuscation can disrupt detection logic by splitting commands or parameters or inserting extra characters (that are ignored by PowerShell).\n",
    "# Monitor for the execution of PowerShell with unusually high counts of characters like ^, +, $, and %.\n",
    "BAD_CHARACTER = {'^', '+', '$', '%'}\n",
    "# Suspicious PowerShell cmdlets\n",
    "# Many of our PowerShell detection analytics look for cmdlets, methods, and switches that may indicate malicious activity.\n",
    "# The following analytic is by no means exhaustive but offers a few valuable examples of suspicious cmdlets and other oft-abused features to look out for:\n",
    "BAD_CMD = {'-nop', '-noni', 'invoke-expression', 'iex', '.downloadstring', 'downloadfile'}\n",
    "BAD_MODULE = {\"__init__\", \"__new__\", \"__reduce__\", \"__builtin__\", \"os\", \"subprocess\", \"sys\", \"builtins\", \"socket\"}\n",
    "BAD_IMPORT = {'module', 'names', 'level', }\n",
    "\n",
    "class scan_pickle_file:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def scann(scan):\n",
    "        with open(scan, 'rb') as f:\n",
    "                print()\n",
    "                scan=(str(f.read()))\n",
    "        print(\"\\n******scanning-pickle******\")\n",
    "        result_output = \"\"\n",
    "        result_total = 0\n",
    "        result_other = 0\n",
    "        result_calls = {}\n",
    "        result_signals = {}\n",
    "        result_files = {}\n",
    "        result_library = {}\n",
    "        result_cmd = {}\n",
    "        result_moudle = {}\n",
    "        result_import = {}\n",
    "\n",
    "        for call in BAD_CALLS:\n",
    "            result_calls[call] = 0\n",
    "        for signal in BAD_SIGNAL:\n",
    "            result_signals[signal] = 0\n",
    "        for file in BAD_FILES:\n",
    "            result_files[file] = 0\n",
    "        for lib in BAD_LIBRARY:\n",
    "            result_library[lib] = 0\n",
    "        for cmd in BAD_CMD:\n",
    "            result_cmd[cmd] = 0\n",
    "        for moudle in BAD_MODULE:\n",
    "            result_moudle[moudle] = 0\n",
    "        for impor in BAD_IMPORT:\n",
    "            result_import[impor] = 0\n",
    "\n",
    "        input = scan\n",
    "        for call in BAD_CALLS:\n",
    "            if (input.find(call) > -1):\n",
    "                result_calls[call] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found lib call (\" + call + \") -----\\n\"\n",
    "                result_output += input\n",
    "\n",
    "        for signal in BAD_SIGNAL:\n",
    "            if (input.find(signal) > -1):\n",
    "                result_signals[signal] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious signal (\" + signal + \") -----\\n\"\n",
    "                result_output += input\n",
    "\n",
    "        for file in BAD_FILES:\n",
    "            if (input.find(file) > -1):\n",
    "                result_files[file] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious file (\" + file + \") -----\\n\"\n",
    "                result_output += input\n",
    "\n",
    "        for lib in BAD_LIBRARY:\n",
    "            if (input.find(lib) > -1):\n",
    "                result_library[lib] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious signal (\" + lib + \") -----\\n\"\n",
    "                result_output += input\n",
    "\n",
    "        for impo in BAD_IMPORT:\n",
    "            if (input.find(impo) > -1):\n",
    "                result_import[impo] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious import (\" + impo + \") -----\\n\"\n",
    "                result_output += input\n",
    "        for cm in BAD_CMD:\n",
    "            if (input.find(cm) > -1):\n",
    "                result_cmd[impo] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious cmd command (\" + cm + \") -----\\n\"\n",
    "                result_output += input\n",
    "        for mod in BAD_MODULE:\n",
    "            if (input.find(mod) > -1):\n",
    "                result_moudle[mod] += 1\n",
    "                result_total += 1\n",
    "                result_output += \"----- found malicious module (\" + mod + \") -----\\n\"\n",
    "                result_output += input\n",
    "\n",
    "        if result_total > 0:\n",
    "            for file in BAD_FILES:\n",
    "                if (result_files[file])>0:\n",
    "                    print(\"malicious file (\" + file + \"): \" + str(result_files[file]))\n",
    "            for lib in BAD_LIBRARY:\n",
    "                if (result_library[lib])>0:\n",
    "                    print(\"malicious lib (\" + lib + \"): \" + str(result_library[lib]))\n",
    "            for call in BAD_CALLS:\n",
    "                if (result_calls[call])>0:\n",
    "                    print(\"library call (\" + call + \".): \" + str(result_calls[call]))\n",
    "            for signal in BAD_SIGNAL:\n",
    "                if (result_signals[signal])>0:\n",
    "                    print(\"malicious signal (\" + signal + \"): \" + str(result_signals[signal]))\n",
    "            for c in BAD_CMD:\n",
    "                if (result_cmd[c])>0:\n",
    "                    print(\"malicious cmd command (\" + c + \"): \" + str(result_cmd[c]))\n",
    "            for m in BAD_MODULE:\n",
    "                if (result_moudle[m])>0:\n",
    "                    print(\"malicious module (\" + m + \"): \" + str(result_moudle[m]))\n",
    "            for i in BAD_IMPORT:\n",
    "                if (result_import[i])>0:\n",
    "                    print(\"malicious import (\" + i + \"): \" + str(result_import[i]))\n",
    "            if (result_other)>0:\n",
    "                print(\"non-standard calls: \" + str(result_other))\n",
    "            # print(\"total: \" + str(result_total))\n",
    "\n",
    "            print(colored(\"SCAN FAILED\\n\", \"red\"))\n",
    "\n",
    "            # print(result_output)\n",
    "            # print(result_total)\n",
    "        else:\n",
    "            print(colored(\"SCAN PASSED!\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38800e11",
   "metadata": {},
   "source": [
    "<img src=\"ariel.png\" alt=\"Image 1\" width=\"150\" style=\"float: left; margin-right: 20px;\">\n",
    "<img src=\"cyber.png\" alt=\"Image 2\" width=\"150\" style=\"float: left;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209580f4",
   "metadata": {},
   "source": [
    "# ModelGuard: disarm and reconstruction\n",
    "### Raz Elbaz\n",
    "### Dr. Ran Dubin and Prof. Amit Dvir\n",
    "\n",
    "#### Student ID: 207276775\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e83e9b",
   "metadata": {},
   "source": [
    "This code first trains the model, saves it as a pickle file, appends the exe file to the pickle file, and then loads the model from the updated pickle file. It performs predictions using the loaded model and fits the new model with the appended exe file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88489fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code loads the MNIST dataset from a compressed pickle file and assigns the training and validation data \n",
    "to variables `train_x`, `train_y`, `valid_x`, and `valid_y`.\n",
    "'''\n",
    "\n",
    "\n",
    "PATH = Path('data') / 'mnist'\n",
    "\n",
    "with gzip.open(PATH / 'mnist.pkl.gz', 'rb') as f:\n",
    "    ((train_x, train_y), (valid_x, valid_y), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20537649",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code sets up the hyperparameters for a machine learning model. \n",
    "It assigns the values 64, 0.1, and 2 to variables `bs`, `lr`, and `epochs`, respectively.\n",
    "It also checks if a CUDA-compatible GPU is available and assigns the device `cuda` if true, \n",
    "or the device `cpu` if false, to the variable `dev`. \n",
    "'''\n",
    "bs = 64\n",
    "lr = 0.1\n",
    "epochs = 2\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd9bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code defines a function called `preprocess` that takes two arguments `x` and `y`. \n",
    "The function preprocesses the input data `x` and target data `y` by reshaping `x` into a 4-dimensional tensor of shape (-1, 1, 28, 28), where `-1` indicates the inferred batch size. It then moves the data to the device specified by the `dev` variable. The function returns the preprocessed `x` and `y` tensors. \n",
    "This function is commonly used in deep learning models to prepare the data for training or inference.\n",
    "'''\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04610c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code defines a function called `get_dataloader` that prepares and returns a data loader for training or evaluation. \n",
    "It takes input data `x` and target data `y`, along with batch size `bs` and shuffle flag `shuffle`. \n",
    "The function creates a data set (`TensorDataset`) from `x` and `y` and then creates a data loader (`DataLoader`) from the dataset with the specified batch size and shuffle behavior. The function wraps the data loader with a preprocessing function and returns the wrapped data loader. \n",
    "This allows for convenient iteration over preprocessed batches of data during model training or evaluation.\n",
    "'''\n",
    "def get_dataloader(x, y, bs, shuffle):\n",
    "    ds = TensorDataset(*map(tensor, (x, y)))\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=shuffle)\n",
    "    return WrappedDataLoader(dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc7fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code creates data loaders `train_dl` and `valid_dl` for training and validation datasets respectively, with specific batch sizes and shuffle settings. \n",
    "These data loaders will be used for iterating over the data during the training process.\n",
    "'''\n",
    "train_dl = get_dataloader(train_x, train_y, bs, shuffle=False)\n",
    "valid_dl = get_dataloader(valid_x, valid_y, bs * 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e27bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code defines a CNN model for image classification using PyTorch's `nn.Sequential` module. It consists of convolutional layers, activation functions, pooling, and a flatten layer. The model is designed to process grayscale images and classify them into 10 different classes. It is moved to the specified device for computation.\n",
    "'''\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten()  # Use nn.Flatten instead of the custom flatten function\n",
    ").to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de08e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code initializes an SGD optimizer for the model's parameters. It uses stochastic gradient descent (SGD) optimization algorithm with a specified learning rate (`lr`) and momentum of 0.9. The optimizer will be used to update the model's parameters during training.\n",
    "'''\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5b810",
   "metadata": {},
   "source": [
    "The `fit` function trains the model for the specified number of epochs using the provided training and validation data loaders. It uses the specified loss function (`F.cross_entropy`) and optimizer (`opt`) to compute the loss and update the model's parameters.\n",
    "\n",
    "During each epoch, the function iterates over the batches of data in the training data loader (`train_dl`), performs forward and backward passes through the model, computes the loss, and applies the optimizer to update the model's parameters.\n",
    "\n",
    "After each epoch, the function evaluates the model's performance on the validation data loader (`valid_dl`) and prints the training and validation metrics, such as the loss and accuracy.\n",
    "\n",
    "In summary, the `fit` function trains the model using the specified parameters and data loaders, optimizing the model's parameters to minimize the loss and improve its performance on the training data while monitoring its performance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b362f5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.36702837975025177\n",
      "1 0.24116524196863173\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc7ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "model_path = PATH / 'model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beac411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the exe file to the pickle file\n",
    "class OpenFile(object):\n",
    "    def __reduce__(self):\n",
    "        return (subprocess.call, ([r\"C:\\Users\\RazEl\\Downloads\\Release\\netcoreapp3.1\\S4VEtheD4TE.exe\"],))\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(OpenFile(), f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb20795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(model_path, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf642f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='background-color: #ff9999; padding: 10px'><h2>You have just been attacked</h2></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"You have just been attacked\"\n",
    "formatted_message = f\"<div style='background-color: #ff9999; padding: 10px'><h2>{message}</h2></div>\"\n",
    "display(Markdown(formatted_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f10692",
   "metadata": {},
   "source": [
    "Now we will open the file in a better way, we will clean the things from it that are considered \"malicious\" and we can safely trust the file - with only \"clean\" files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98568331",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as f:\n",
    "    obj = Pickled.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb382a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='background-color: #99ff99; padding: 10px'><h2>You are protected! Now we will remove the malware using the CDR library and you can load the files safely</h2></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"You are protected! Now we will remove the malware using the CDR library and you can load the files safely\"\n",
    "formatted_message = f\"<div style='background-color: #99ff99; padding: 10px'><h2>{message}</h2></div>\"\n",
    "display(Markdown(formatted_message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff47d6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-------------------------- data\\mnist\\model ----------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Fickling failed to detect any overtly unsafe code, but the pickle file may still be unsafe.\n",
      "\n",
      "Do not unpickle this file if it is from an untrusted source!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "clean"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_file(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c04778c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"background-color: #FFD700; padding: 10px;\"><h2>Now we will load the files in the safe way and in the unsafe way</h2></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = \"Now we will load the files in the safe way and in the unsafe way\"\n",
    "formatted_message = f'<div style=\"background-color: #FFD700; padding: 10px;\"><h2>{message}</h2></div>'\n",
    "display(Markdown(formatted_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0fdff",
   "metadata": {},
   "source": [
    "### Safe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9976b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as f:\n",
    "    obj = Pickled.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024424dc",
   "metadata": {},
   "source": [
    "### Unsafe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638f106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'rb') as f:\n",
    "    obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee8dac",
   "metadata": {},
   "source": [
    "### Now we would like to generate a prediction for the pickle file after it has been sanitized (using the cdr.py library) of the malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ad732a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"background-color: #66CDAA; padding: 10px;\"><h2>&#x1F512; CDR is the safe way to load files :)</h2></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "message = \"CDR is the safe way to load files :)\"\n",
    "background_color = \"#66CDAA\"\n",
    "lock_icon = \"&#x1F512;\"  # Unicode for lock icon\n",
    "\n",
    "formatted_message = f'<div style=\"background-color: {background_color}; padding: 10px;\"><h2>{lock_icon} {message}</h2></div>'\n",
    "Markdown(formatted_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b350a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model object to a pickle file\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "058d8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model object from the pickle file\n",
    "with open(model_path, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b7121fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions using the loaded model\n",
    "# Example prediction code:\n",
    "input_0 = valid_x[0]  # Input with label 0\n",
    "input_1 = valid_x[1]  # Input with label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2453dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code snippet takes an input sample, converts it into a tensor, feeds it through the loaded model, and obtains the predicted class.\n",
    "'''\n",
    "\n",
    "input_tensor_0 = tensor(input_0).view(1, 1, 28, 28).to(dev)\n",
    "prediction_0 = loaded_model(input_tensor_0)\n",
    "predicted_class_0 = prediction_0.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d208dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code takes another input sample, converts it into a tensor, passes it through the loaded model, and retrieves the predicted class.\n",
    "'''\n",
    "input_tensor_1 = tensor(input_1).view(1, 1, 28, 28).to(dev)\n",
    "prediction_1 = loaded_model(input_tensor_1)\n",
    "predicted_class_1 = prediction_1.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3bbdf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for input 0: 3\n",
      "Predicted class for input 1: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class for input 0:\", predicted_class_0)\n",
    "print(\"Predicted class for input 1:\", predicted_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbc80a",
   "metadata": {},
   "source": [
    "### Fit the new model after removing the exe file that activated the ransomware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56536876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24116524057388306\n",
      "1 0.24116524257659913\n"
     ]
    }
   ],
   "source": [
    "# Fit the new model after removing the exe file that activated the ransomware\n",
    "fit(epochs, loaded_model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815e06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
